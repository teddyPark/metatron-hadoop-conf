spark.driver.extraClassPath= 
spark.driver.extraLibraryPath=/usr/local/hadoop/lib/native:/usr/local/hadoop/lib/native/Linux-amd64-64
spark.eventLog.dir=hdfs:///spark-history/
spark.eventLog.enabled=true
spark.executor.extraJavaOptions=-XX:+UseNUMA
spark.executor.extraLibraryPath=/usr/local/hadoop/lib/native:/usr/local/hadoop/lib/native/Linux-amd64-64
spark.extraListeners= 
spark.history.fs.cleaner.enabled=true
spark.history.fs.cleaner.interval=7d
spark.history.fs.cleaner.maxAge=90d
spark.history.fs.logDirectory=hdfs:///spark-history/
spark.history.kerberos.keytab=none
spark.history.kerberos.principal=none
spark.history.provider=org.apache.spark.deploy.history.FsHistoryProvider
spark.history.store.path=/var/lib/spark2/shs_db
spark.history.ui.port=18081
spark.io.compression.lz4.blockSize=128kb
spark.master=yarn
spark.shuffle.file.buffer=1m
spark.shuffle.io.backLog=8192
spark.shuffle.io.serverThreads=128
spark.shuffle.unsafe.file.output.buffer=5m
spark.sql.autoBroadcastJoinThreshold=26214400
spark.sql.hive.convertMetastoreOrc=true
spark.sql.hive.metastore.jars=/usr/local/hive/lib/*
spark.sql.hive.metastore.version=3.1.2
spark.sql.orc.filterPushdown=true
spark.sql.orc.impl=native
spark.sql.queryExecutionListeners= 
spark.sql.statistics.fallBackToHdfs=true
spark.sql.streaming.streamingQueryListeners= 
spark.sql.warehouse.dir=/apps/spark/warehouse
spark.unsafe.sorter.spill.reader.buffer.size=1m
spark.yarn.dist.files= 
spark.yarn.historyServer.address=master1.metatron:18081
spark.yarn.queue=default
    
